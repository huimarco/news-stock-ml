{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1: Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj_login_page = 'https://sso.accounts.dowjones.com/login-page?client_id=5hssEAdMy0mJTICnJNvC9TXEw3Va7jfO&redirect_uri=https%3A%2F%2Fwww.wsj.com%2Fclient%2Fauth&response_type=code&scope=openid%20idp_id%20roles%20tags%20email%20given_name%20family_name%20uuid%20djid%20djUsername%20djStatus%20trackid%20prts%20updated_at%20created_at%20offline_access&ui_locales=en-us-x-wsj-223-2&nonce=1b34552c-ac89-4605-81d9-5b552a7452a0&state=nmfLpXnMOWJLlEjK.ifKgeElwMAfxoWUUCsEZVu2q-WgzWtwQKEy_EyvQbTs&resource=https%253A%252F%252Fwww.wsj.com%252F&protocol=oauth2&client=5hssEAdMy0mJTICnJNvC9TXEw3Va7jfO#!/signin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(username, password):\n",
    "    login_url = wsj_login_page\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # Create a session object to persist the login session\n",
    "    with requests.Session() as session:\n",
    "        # Send a POST request with login credentials\n",
    "        login_data = {\n",
    "            \"username\": username,\n",
    "            \"password\": password\n",
    "        }\n",
    "        response = session.post(login_url, headers=headers, data=login_data)\n",
    "\n",
    "        # Check if login was successful (you might need to customize this condition)\n",
    "        if response.status_code == 200:\n",
    "            return session\n",
    "        else:\n",
    "            print(\"Login failed:\", response.status_code)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_headlines(session, technology_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # Use the session object to access the technology section page\n",
    "    response = session.get(technology_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        # Scrape the headlines from the technology section page using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        headlines = [headline.text.strip() for headline in soup.find_all(\"a\", class_=\"WSJTheme--headline--unZqjb45\")]\n",
    "        return headlines\n",
    "    else:\n",
    "        print(\"Failed to access technology section page:\", response.status_code)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login failed: 404\n"
     ]
    }
   ],
   "source": [
    "username = 'mallika101@hotmail.com'\n",
    "password = 'abc123'\n",
    "session = login(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if session:\n",
    "    technology_url = \"https://www.wsj.com/news/technology\"  # URL of the technology section\n",
    "    headlines = scrape_headlines(session, technology_url)\n",
    "    print(headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2: Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a WebDriver (you need to have chromedriver installed in your system and its path added to the environment variables)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://www.wsj.com/news/archive/2024/03/21?page=3\"\n",
    "\n",
    "# Open the webpage\n",
    "driver.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "topics = []\n",
    "headlines = []\n",
    "published_times = []\n",
    "\n",
    "# Find all articles on the page\n",
    "articles = soup.find_all(\"article\")\n",
    "\n",
    "# Extract data from each article\n",
    "for article in articles:\n",
    "    # Extract topic\n",
    "    topic = article.find(\"div\", class_=\"WSJTheme--articleType--34Gt-vdG\").text.strip()\n",
    "    topics.append(topic)\n",
    "    \n",
    "    # Extract headline\n",
    "    headline = article.find(\"span\", class_=\"WSJTheme--headlineText--He1ANr9C\").text.strip()\n",
    "    headlines.append(headline)\n",
    "    \n",
    "    # Extract published time\n",
    "    published_time = article.find(\"p\", class_=\"WSJTheme--timestamp--22sfkNDv\").text.strip()\n",
    "    published_times.append(published_time)\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "data = {\n",
    "    \"Topic\": topics,\n",
    "    \"Headline\": headlines,\n",
    "    \"Published Time\": published_times\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Published Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heard on the street</td>\n",
       "      <td>Micron Finally Earns Its AI Premium</td>\n",
       "      <td>12:14 PM ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exclusive</td>\n",
       "      <td>China’s Xi Jinping to Woo U.S. CEOs in Beijing</td>\n",
       "      <td>12:03 PM ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On Trend</td>\n",
       "      <td>From Surviving Auschwitz to Dressing President...</td>\n",
       "      <td>12:01 PM ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Off Duty Travel</td>\n",
       "      <td>A Visit to a Historic Mississippi Port Reveals...</td>\n",
       "      <td>12:00 PM ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business</td>\n",
       "      <td>Nelson Peltz Wins Key Endorsement in Disney Ba...</td>\n",
       "      <td>11:36 AM ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Commentary</td>\n",
       "      <td>The View From Israel’s Front With Hezbollah</td>\n",
       "      <td>11:31 AM ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>essay</td>\n",
       "      <td>Judaism Is a Religion of the Heart</td>\n",
       "      <td>11:30 AM ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Political Economics</td>\n",
       "      <td>Maybe Monetary Policy Needs More Politics, Not...</td>\n",
       "      <td>11:29 AM ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bookshelf</td>\n",
       "      <td>‘Perplexing Paradoxes’ Review: Straining Credu...</td>\n",
       "      <td>11:17 AM ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>Gavin Newsom’s Homelessness Measure Succeeded—...</td>\n",
       "      <td>11:10 AM ET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Topic                                           Headline  \\\n",
       "0  heard on the street                Micron Finally Earns Its AI Premium   \n",
       "1            Exclusive     China’s Xi Jinping to Woo U.S. CEOs in Beijing   \n",
       "2             On Trend  From Surviving Auschwitz to Dressing President...   \n",
       "3      Off Duty Travel  A Visit to a Historic Mississippi Port Reveals...   \n",
       "4             Business  Nelson Peltz Wins Key Endorsement in Disney Ba...   \n",
       "5           Commentary        The View From Israel’s Front With Hezbollah   \n",
       "6                essay                 Judaism Is a Religion of the Heart   \n",
       "7  Political Economics  Maybe Monetary Policy Needs More Politics, Not...   \n",
       "8            Bookshelf  ‘Perplexing Paradoxes’ Review: Straining Credu...   \n",
       "9                 U.S.  Gavin Newsom’s Homelessness Measure Succeeded—...   \n",
       "\n",
       "  Published Time  \n",
       "0    12:14 PM ET  \n",
       "1    12:03 PM ET  \n",
       "2    12:01 PM ET  \n",
       "3    12:00 PM ET  \n",
       "4    11:36 AM ET  \n",
       "5    11:31 AM ET  \n",
       "6    11:30 AM ET  \n",
       "7    11:29 AM ET  \n",
       "8    11:17 AM ET  \n",
       "9    11:10 AM ET  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a WebDriver (you need to have chromedriver installed in your system and its path added to the environment variables)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://www.wsj.com/news/archive/2024/03/21?page=3\"\n",
    "\n",
    "# Open the webpage\n",
    "driver.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
